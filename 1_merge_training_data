#!/bin/bash

###################################################################################################################
#                                                                                                                 #
# Returns the distinct words of a column from a csv file and their number of occurence                            #
#                                                                                                                 #
# usage:                                                                                                          #
# -sd={sourcedirectory}                                                                                              #
# -td={targetdirectory}                                                                                              #
# -tf={file}                                                                                                      #
#                                                                                                                 #
# 	~$ ./1_merge_training_data -sd=./_ds_task/training_files/ -td=./ -f=all_history.csv                           #
#                                                                                                                 #
###################################################################################################################


# the following arguments should be provided by the user of this bash script
for i in "$@"
do
case $i in
    -sd=*|--sourcedirectory=*)
		SourceDirectory="${i#*=}"
		shift # past argument=value
    ;;
    -td=*|--targetDirectory=*)
		TargetDirectory="${i#*=}"
		shift # past argument=value
    ;;
    -f=*|--file=*)
		File="${i#*=}"
		shift # past argument=value
    ;;
    *)
        # unknown option
    ;;
esac
done

# detecting the current directory
baseline=$PWD

# dropping previous file
rm -f $TargetDirectory$File

# creating new merged file with appropiate header ("date" column will be added)
cd "${SourceDirectory/[.]/$baseline}"
first=$(ls | sort -n | head -1)
head -n+1 $first > tmp.csv
awk -F"," -v col="date" -v OFS="," '{print col, $0}' tmp.csv > "${TargetDirectory/[.]/$baseline}"$File
rm -f tmp.csv

# appending those daily files into a merged one
# plus adding "date" values from filenames into the first column
cd "${SourceDirectory/[.]/$baseline}"
for pathfilename in "${SourceDirectory/[.]/$baseline}"*
do 
	filename=$(echo $pathfilename | tail -c 11)
	echo $filename
	awk -F"," -v col="$filename" -v OFS="," '{print col, $0}' $pathfilename | tail -n+2 >> "${TargetDirectory/[.]/$baseline}"$File
done 

# celebrate
echo "The historical data have merged into all_history.csv."
ls -al "${TargetDirectory/[.]/$baseline}"$File        

# step back to original directory
cd $baseline  




